import os
import hashlib
from datetime import datetime
from typing import List

# 1. Import th∆∞ vi·ªán c·ªßa b·∫°n
import torch
from transformers import AutoTokenizer, AutoModel, RobertaModel
from langchain_core.embeddings import Embeddings # Class cha ƒë·ªÉ custom
from langchain_pinecone import PineconeVectorStore
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser
from langchain_core.runnables import RunnablePassthrough

from app.core.config import settings
from app.services.llm_engine import get_llm
from app.services.blockchain import BlockchainService

# ---------------------------------------------------------
# 2. ƒê·ªäNH NGHƒ®A CLASS CUSTOM EMBEDDING (D√πng code c·ªßa b·∫°n)
# ---------------------------------------------------------
class VietnameseSBERTEmbeddings(Embeddings):
    def __init__(self, model_name: str = "keepitreal/vietnamese-sbert"):
        try:
            self.tokenizer = AutoTokenizer.from_pretrained(model_name)
            # Thay AutoModel b·∫±ng RobertaModel
            self.model = RobertaModel.from_pretrained(model_name)
            self.device = "cuda" if torch.cuda.is_available() else "cpu"
            self.model.to(self.device)
            self.model.eval()
        except Exception as e:
            raise RuntimeError(f"Failed to load model: {e}")

    def _compute_embedding(self, texts: List[str]) -> List[List[float]]:
        try:
            # Tokenize v·ªõi max_length ƒë·ªÉ tr√°nh qu√° d√†i
            encoded_input = self.tokenizer(
                texts, 
                padding=True, 
                truncation=True, 
                max_length=512,  # Th√™m gi·ªõi h·∫°n
                return_tensors='pt'
            )
            encoded_input = {k: v.to(self.device) for k, v in encoded_input.items()}

            with torch.no_grad():
                model_output = self.model(**encoded_input)

            sentence_embeddings = self._mean_pooling(
                model_output, 
                encoded_input['attention_mask']
            )
            
            return sentence_embeddings.cpu().tolist()
        except Exception as e:
            raise RuntimeError(f"Embedding computation failed: {e}")

    def embed_documents(self, texts: List[str]) -> List[List[float]]:
        """D√πng cho list vƒÉn b·∫£n (Khi n·∫°p data)"""
        return self._compute_embedding(texts)

    def embed_query(self, text: str) -> List[float]:
        """D√πng cho 1 c√¢u h·ªèi (Khi chat)"""
        return self._compute_embedding([text])[0]

# ---------------------------------------------------------
# 3. S·ª¨ D·ª§NG CLASS M·ªöI TRONG RAG SERVICE
# ---------------------------------------------------------
class RAGService:
    def __init__(self):
        # Thay v√¨ d√πng HuggingFaceEmbeddings c√≥ s·∫µn, ta d√πng Class t·ª± vi·∫øt
        self.embedding_model = VietnameseSBERTEmbeddings()

        # K·∫øt n·ªëi Pinecone
        self.vector_db = PineconeVectorStore.from_existing_index(
            index_name=settings.PINECONE_INDEX_NAME,
            embedding=self.embedding_model
        )
        
        self.retriever = self.vector_db.as_retriever(search_kwargs={"k": 3})
        self.llm = get_llm(streaming=True)
        
        self.prompt = ChatPromptTemplate.from_template("""
        <|im_start|>system
        B·∫°n l√† ViLaw, tr·ª£ l√Ω ph√°p l√Ω.
        Ng·ªØ c·∫£nh:
        {context}
        <|im_end|>
        
        <|im_start|>user
        C√¢u h·ªèi: {question}
        <|im_end|>
        
        <|im_start|>assistant
        """)

    def format_docs(self, docs):
        return "\n\n".join(doc.page_content for doc in docs)

    async def chat_stream(self, question: str):
        chain = (
            {"context": self.retriever | self.format_docs, "question": RunnablePassthrough()}
            | self.prompt
            | self.llm
            | StrOutputParser()
        )

        full_response = ""
        async for chunk in chain.astream(question):
            full_response += chunk
            yield chunk

        tx_hash = BlockchainService.create_hash(full_response)
        yield f"\n\n[üõ°Ô∏è HASH: {tx_hash}]"